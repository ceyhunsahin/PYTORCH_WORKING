{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e33479",
   "metadata": {},
   "source": [
    "# PYTORCH SESSION_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2fb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1710b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.0710e-01, 1.4141e+00, 1.0000e+00, 8.6500e+02],\n",
       "        [8.2450e-01, 2.0000e+00, 3.4220e+03, 5.2324e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[0.7071,1.4141,1,865],\n",
    "                  [0.8245, 2,3422,5.2324]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d58e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068474cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05101730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3422.)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b05890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[1,2] = 3.4222\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d5f1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4221999645233154"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1,2].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228ca020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.4141,   1.0000, 865.0000],\n",
       "        [  2.0000,   3.4222,   5.2324]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85e9088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7071, 1.0000],\n",
       "        [0.8245, 3.4222]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a1c37",
   "metadata": {},
   "source": [
    "## None adds a new (size 1) dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9916398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4222)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a5c7c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4222])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1,2,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f916d57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.4222), tensor([3.4222]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1,2],t[1,2,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7290d15",
   "metadata": {},
   "source": [
    "# Advanced Indexing with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6130bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[t<1] = 0\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edbd9036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ True, False, False, False],\n",
       "         [ True, False, False, False]]),\n",
       " tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "         [  0.0000,   2.0000,   3.4222,   5.2324]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t < 1, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d07f1",
   "metadata": {},
   "source": [
    "# TENSOR ELEMENTS TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e353b",
   "metadata": {},
   "source": [
    "- torch.float32 aka torch.float\n",
    "- torch.float64 aka torch.double\n",
    "- torch.float16 aka half, bf16\n",
    "- int8, uint8, int16,int32/int, int64/long\n",
    "- torch.bool\n",
    "- torch.complex32, complex64, complex128 (with half/float/double real and imaginary part)\n",
    "- torch.quint8 for quantized tensors\n",
    "\n",
    "- <i> for pytorch </i> float32 is the most common dtype\n",
    "- <i> for indexing </i> int64 is often used, but int32 can be muchfaster if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c5c2200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9ffea",
   "metadata": {},
   "source": [
    "### Specify dtype in factory functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4feb5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,3), dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01fd3b",
   "metadata": {},
   "source": [
    "#### Convert if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c5790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3db568b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f1bb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   1, 865],\n",
       "        [  0,   2,   3,   5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c05c4d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4219,   5.2305]], dtype=torch.float16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.to(torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b54abf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   1, 865],\n",
       "        [  0,   2,   3,   5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.to(torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ee903ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31586a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4219,   5.2305]], dtype=torch.float16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "831fb216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.long()\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac27dfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   1, 865],\n",
       "        [  0,   2,   3,   5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09869eea",
   "metadata": {},
   "source": [
    "# PUTTING TENSORS ON THE GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3882ed",
   "metadata": {},
   "source": [
    "#### Tensors have a device, we can move between devices and just as we convert between dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9623eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5a4ac8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4219,   5.2305]], dtype=torch.float16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.to(dtype = torch.half)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b0e60",
   "metadata": {},
   "source": [
    "# TENSOR-A SCENIC VIEW OF MEMORY BLOBS\n",
    "\n",
    "#### Internally, Tensors are (most often) stored as a blob of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2d191a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e531c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0\n",
       " 1.4141000509262085\n",
       " 1.0\n",
       " 865.0\n",
       " 0.0\n",
       " 2.0\n",
       " 3.4221999645233154\n",
       " 5.232399940490723\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 8]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc67e28",
   "metadata": {},
   "source": [
    "#### METADATA of tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01704f45",
   "metadata": {},
   "source": [
    "- The size, stride and offset and data pointer(data_ptr)(in addition to device and dtype) are key tensor <i>metadata</i>. They perform Pytorch of how it should resolve a tensor location to a memory location.\n",
    "\n",
    "- The metadata is always stored on the CPU, but typically provided to CUDA kernels as we go along.\n",
    "\n",
    "- So in the examples, the index <code>t[1,2]</code> transforms into the memory location <code>1 * t.stride(0) + 2 * t.stride(1) = 1 * 4 + 2 * 1</code>, i.e. memory location 6 (with 0-based counting)\n",
    "\n",
    "- A tensor where the strides as descending and there are no \"gaps\" in the storage is called <code>contiguous</code>. You can force to get one (by coping as needed) through <code>t = t.contiguous()</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "522876e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf3faf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf89dab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0288cb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140669039429952"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e239bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4222)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98af56a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1551, 0.2202, 0.0667, 0.9987, 0.0650],\n",
       "        [0.6958, 0.6001, 0.0791, 0.1937, 0.0066],\n",
       "        [0.7979, 0.1320, 0.2372, 0.4751, 0.9901]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.rand((3,5))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffd2ad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.15508830547332764\n",
       " 0.22020792961120605\n",
       " 0.0666506290435791\n",
       " 0.9986899495124817\n",
       " 0.06496840715408325\n",
       " 0.6957641839981079\n",
       " 0.600147008895874\n",
       " 0.0791136622428894\n",
       " 0.19369953870773315\n",
       " 0.006577432155609131\n",
       " 0.7978680729866028\n",
       " 0.1319788694381714\n",
       " 0.23716026544570923\n",
       " 0.475127637386322\n",
       " 0.9900521039962769\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 15]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02a9c47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1), torch.Size([3, 5]), 0, 140668998881600, 140668998881600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stride(), v.shape, v.storage_offset(), v.data_ptr(), v.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c9be578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7364, 0.0352, 0.0414],\n",
       "        [0.0890, 0.9103, 0.3119],\n",
       "        [0.5576, 0.4658, 0.7648]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.rand((3,5)) # It works as a default V values\n",
    "v = v[:, 2:]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aab2234d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.5733586549758911\n",
       " 0.661700427532196\n",
       " 0.7363727688789368\n",
       " 0.035160183906555176\n",
       " 0.04139518737792969\n",
       " 0.30858278274536133\n",
       " 0.7208130955696106\n",
       " 0.08901572227478027\n",
       " 0.9102987051010132\n",
       " 0.31191879510879517\n",
       " 0.3560728430747986\n",
       " 0.6295565366744995\n",
       " 0.5576223134994507\n",
       " 0.465814471244812\n",
       " 0.7647926807403564\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 15]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.storage() # It works as a default V values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34b6f159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1), torch.Size([3, 3]), 2, 140668996562568, 140668996562560)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stride(), v.shape, v.storage_offset(), v.data_ptr(), v.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adbc92d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.contiguous()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c45e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.5733586549758911\n",
       " 0.661700427532196\n",
       " 0.7363727688789368\n",
       " 0.035160183906555176\n",
       " 0.04139518737792969\n",
       " 0.30858278274536133\n",
       " 0.7208130955696106\n",
       " 0.08901572227478027\n",
       " 0.9102987051010132\n",
       " 0.31191879510879517\n",
       " 0.3560728430747986\n",
       " 0.6295565366744995\n",
       " 0.5576223134994507\n",
       " 0.465814471244812\n",
       " 0.7647926807403564\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 15]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da9716",
   "metadata": {},
   "source": [
    "### <code>contiguous </code> in PyTorch means if the neighboring elements in the tensor are actually next to each other in memory. Let’s take a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e01d6654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]]) # x is contiguous\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf2e1f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 6]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "725f13c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.transpose(0, 1) # y is non-contiguous\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd6b4881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 6]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbdacaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668998068736"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc5830aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140668998068736"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a807175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43c52000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(y.is_contiguous())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d023ce",
   "metadata": {},
   "source": [
    "Since x is contiguous, <code>x[0][0] and x[0][1] </code> are <b>next to each other in memory</b>. But <code>y[0][0] and y[0][1] </code>is not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a4680c",
   "metadata": {},
   "source": [
    "# COMMON VIEW-CREATING OPERATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200cca95",
   "metadata": {},
   "source": [
    "- <code>.t()</code>, <code>.transpose(...)</code>, <code>.permute(...)</code> : change the order of axes in the stride/size metadata,\n",
    "\n",
    "- <code>.view(...)</code>: change the stride/size\n",
    "\n",
    "- (Single) Indexing: drops one dimension, changes offset for indices other than <code>0</code>\n",
    "\n",
    "- slicing, <code>.narrow</code> : reduces sizes, change offset, interleave <code>(::2)</code> changes stride\n",
    "\n",
    "- <code>.as_strided</code> : replaces the stride/size metadata with something else, powerful but <b>dangerous </b> in the sense that there are no sanity checks\n",
    "\n",
    "Special Case: <code>reshape</code> creates view(like <code>view</code>) if possible and copies the tensor if not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c60920d",
   "metadata": {},
   "source": [
    "<h3><code>view() vs transpose()</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540895b7",
   "metadata": {},
   "source": [
    "<code>transpose()</code>, like <code>view()</code> can also be used to change the shape of a tensor and it also returns a new tensor sharing the data with the original tensor:\n",
    "\n",
    "\n",
    "\n",
    "One difference is that <code>view() </code>can only operate on contiguous tensor and the returned tensor is still contiguous. <code>transpose()</code> can operate both on contiguous and non-contiguous tensor. Unlike <code>view()</code>, the returned tensor may be not contiguous any more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f745f99",
   "metadata": {},
   "source": [
    "<h3><code>permut() vs transpose()</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfb787",
   "metadata": {},
   "source": [
    "<code>permute()</code> and <code>tranpose()</code> are similar. <code>transpose()</code> can only swap two dimension. But <code>permute()</code>can swap all the dimensions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21adfee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4425, 0.0897, 0.1937, 0.4093, 0.1829],\n",
       "        [0.3224, 0.2922, 0.1216, 0.4738, 0.3364],\n",
       "        [0.6190, 0.9352, 0.2751, 0.4832, 0.3374],\n",
       "        [0.8232, 0.3731, 0.5171, 0.8361, 0.8033]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.rand((4,5))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be47efdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12b406be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4425, 0.3224, 0.6190, 0.8232],\n",
       "        [0.0897, 0.2922, 0.9352, 0.3731],\n",
       "        [0.1937, 0.1216, 0.2751, 0.5171],\n",
       "        [0.4093, 0.4738, 0.4832, 0.8361],\n",
       "        [0.1829, 0.3364, 0.3374, 0.8033]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c3b0a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4425, 0.3224, 0.6190, 0.8232],\n",
       "        [0.0897, 0.2922, 0.9352, 0.3731],\n",
       "        [0.1937, 0.1216, 0.2751, 0.5171],\n",
       "        [0.4093, 0.4738, 0.4832, 0.8361],\n",
       "        [0.1829, 0.3364, 0.3374, 0.8033]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transpose(0,1) # dim0 <----> dim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e173c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ba52938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4425, 0.3224, 0.6190, 0.8232],\n",
       "        [0.0897, 0.2922, 0.9352, 0.3731],\n",
       "        [0.1937, 0.1216, 0.2751, 0.5171],\n",
       "        [0.4093, 0.4738, 0.4832, 0.8361],\n",
       "        [0.1829, 0.3364, 0.3374, 0.8033]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.permute(1,0) # we have 2 dimensions so we can change them by order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2c1fdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4425, 0.0897, 0.1937, 0.4093],\n",
       "        [0.1829, 0.3224, 0.2922, 0.1216],\n",
       "        [0.4738, 0.3364, 0.6190, 0.9352],\n",
       "        [0.2751, 0.4832, 0.3374, 0.8232],\n",
       "        [0.3731, 0.5171, 0.8361, 0.8033]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.view(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87037557",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ab92369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98f95c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = x.transpose(1, 2) # change dim1 and dim2\n",
    "\n",
    "z = x.permute(2, 1, 0) # change dim2, dim1, dim0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9fa2a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5759, 0.9303, 0.5310],\n",
       "         [0.6915, 0.9892, 0.5281],\n",
       "         [0.1817, 0.5255, 0.5200],\n",
       "         [0.8090, 0.5901, 0.0245],\n",
       "         [0.1847, 0.3170, 0.1333]],\n",
       "\n",
       "        [[0.3970, 0.4477, 0.7566],\n",
       "         [0.6152, 0.2231, 0.2015],\n",
       "         [0.4656, 0.2867, 0.9432],\n",
       "         [0.7010, 0.1540, 0.4959],\n",
       "         [0.4672, 0.9662, 0.0609]],\n",
       "\n",
       "        [[0.7007, 0.3559, 0.1589],\n",
       "         [0.4868, 0.6171, 0.9794],\n",
       "         [0.3041, 0.0865, 0.8772],\n",
       "         [0.6889, 0.2504, 0.3014],\n",
       "         [0.8451, 0.3904, 0.8351]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b4ee381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5759, 0.6915, 0.1817, 0.8090, 0.1847],\n",
       "         [0.9303, 0.9892, 0.5255, 0.5901, 0.3170],\n",
       "         [0.5310, 0.5281, 0.5200, 0.0245, 0.1333]],\n",
       "\n",
       "        [[0.3970, 0.6152, 0.4656, 0.7010, 0.4672],\n",
       "         [0.4477, 0.2231, 0.2867, 0.1540, 0.9662],\n",
       "         [0.7566, 0.2015, 0.9432, 0.4959, 0.0609]],\n",
       "\n",
       "        [[0.7007, 0.4868, 0.3041, 0.6889, 0.8451],\n",
       "         [0.3559, 0.6171, 0.0865, 0.2504, 0.3904],\n",
       "         [0.1589, 0.9794, 0.8772, 0.3014, 0.8351]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e42a58d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6bec902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5759, 0.3970, 0.7007],\n",
       "         [0.6915, 0.6152, 0.4868],\n",
       "         [0.1817, 0.4656, 0.3041],\n",
       "         [0.8090, 0.7010, 0.6889],\n",
       "         [0.1847, 0.4672, 0.8451]],\n",
       "\n",
       "        [[0.9303, 0.4477, 0.3559],\n",
       "         [0.9892, 0.2231, 0.6171],\n",
       "         [0.5255, 0.2867, 0.0865],\n",
       "         [0.5901, 0.1540, 0.2504],\n",
       "         [0.3170, 0.9662, 0.3904]],\n",
       "\n",
       "        [[0.5310, 0.7566, 0.1589],\n",
       "         [0.5281, 0.2015, 0.9794],\n",
       "         [0.5200, 0.9432, 0.8772],\n",
       "         [0.0245, 0.4959, 0.3014],\n",
       "         [0.1333, 0.0609, 0.8351]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca6f9fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d701ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 5])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5cb19146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8babffb",
   "metadata": {},
   "source": [
    "<h2><code>torch.narrow(input, dim, start, length)</code></h2>\n",
    "\n",
    "Returns a new tensor that is a narrowed version of input tensor. The dimension dim is input from start to start + length. The returned tensor and input tensor share the same underlying storage.\n",
    "\n",
    "- input (Tensor) – the tensor to narrow\n",
    "\n",
    "- dim (int) – the dimension along which to narrow\n",
    "\n",
    "- start (Tensor or int) – the starting dimension\n",
    "\n",
    "- length (int) – the distance to the ending dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2961f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2885f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0043a0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [6],\n",
       "        [9]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(x, 1,2,1) # dim0 = rows, dim1 = columns, starts with 2.column and continue by length (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91bb2c",
   "metadata": {},
   "source": [
    "# IF YOU NEED A COPY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5194d1",
   "metadata": {},
   "source": [
    "You can use <code>t.colone()</code> to forcefullt create a copy(or <code>.to(device = ..., dtype = ...., copy = True)</code>) if you need a conversion that is guaranteed to copy if the tensor is alreadyin the right form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18f74ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = t.clone()\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba637718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140669039429952,\n",
       " 140668996561344,\n",
       " tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "         [  0.0000,   2.0000,   3.4222,   5.2324]]),\n",
       " tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "         [  0.0000,   2.0000,   3.4222,   5.2324]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data_ptr(), t2.data_ptr(), t, t2 # different address, same content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75cfdc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.is_contiguous(), t2.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd899b",
   "metadata": {},
   "source": [
    "# GENERALIZED TENSORS ARE TENSORS, TOO.\n",
    "\n",
    "- These were strided tensors\n",
    "- There are other Tensor types  : Sparse, on TPU, ...\n",
    "- Quantized is a bit special, but similar in spirit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e21f075e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.strided"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "05aef895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(indices=tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
       "        values=tensor([-0.5729, -0.5428,  2.0772, -0.7035, -0.4382,  0.5783,\n",
       "                        0.5230, -0.6898, -0.7627,  0.3398]),\n",
       "        size=(10,), nnz=10, layout=torch.sparse_coo),\n",
       " torch.sparse_coo)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.sparse_coo_tensor(torch.arange(10)[None], torch.randn(10))\n",
    "s, s.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a85fef",
   "metadata": {},
   "source": [
    "# SAVING AND LOADING TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e64752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.4141,   1.0000, 865.0000],\n",
       "        [  0.0000,   2.0000,   3.4222,   5.2324]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(t, 'my_tensor.pt')\n",
    "torch.load('my_tensor.pt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557834c",
   "metadata": {},
   "source": [
    "# INPLACE OPERATIONS\n",
    "\n",
    "Inplace operations modify their inputs instead of creating a new tensors as outputs are signaled by a trailing underscore _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb0fac34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1992, 0.0078, 0.5014],\n",
       "         [0.3508, 0.1924, 0.9293]]),\n",
       " 140669002752832)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2,3)\n",
    "a,a.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e8c1750a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3546, 0.0758, 0.7404],\n",
       "        [0.7547, 0.6348, 0.5306]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(2,3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7de1a0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5537, 0.0836, 1.2418],\n",
       "         [1.1055, 0.8272, 1.4599]]),\n",
       " 140669002752832)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(b), a.data_ptr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d17ea976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1992, 0.0078, 0.5014],\n",
       "        [0.3508, 0.1924, 0.9293]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a # after adding b parameter, a value doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "615a0c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5537, 0.0836, 1.2418],\n",
       "         [1.1055, 0.8272, 1.4599]]),\n",
       " tensor([[0.5537, 0.0836, 1.2418],\n",
       "         [1.1055, 0.8272, 1.4599]]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(b), a # after adding b parameter a value modified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
