{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s1): Sigmoid()\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.s1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "        self.s2 = nn.Sigmoid()\n",
    "        self.fc1.weight = torch.nn.Parameter(torch.Tensor([[0.15,0.2],[0.250,0.30]]))\n",
    "        self.fc1.bias = torch.nn.Parameter(torch.Tensor([0.35]))\n",
    "        self.fc2.weight = torch.nn.Parameter(torch.Tensor([[0.4,0.45],[0.5,0.55]]))\n",
    "        self.fc2.bias = torch.nn.Parameter(torch.Tensor([0.6]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.fc1(x)\n",
    "        x = self.s1(x)\n",
    "        x= self.fc2(x)\n",
    "        x = self.s2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.1500, 0.2000],\n",
      "        [0.2500, 0.3000]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3500], requires_grad=True), Parameter containing:\n",
      "tensor([[0.4000, 0.4500],\n",
      "        [0.5000, 0.5500]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6000], requires_grad=True)]\n",
      "weight2 Parameter containing:\n",
      "tensor([[0.4000, 0.4500],\n",
      "        [0.5000, 0.5500]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.0500, 0.1000])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters: weight and bias\n",
    "print(list(net.parameters()))\n",
    "# input data\n",
    "weight2 = list(net.parameters())[2]\n",
    "print('weight2',weight2)\n",
    "data = torch.Tensor([0.05,0.1]);data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.2984, grad_fn=<MseLossBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of last layer\n",
    "out = net(data)\n",
    "target = torch.Tensor([0.01,0.99])  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple hook class that returns the input and output of a layer during forward/backward pass\n",
    "class Hook():\n",
    "    net = Net()\n",
    "\n",
    "    def __init__(self, module, backward=False):\n",
    "        if backward==False:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fc1', Linear(in_features=2, out_features=2, bias=True)), ('s1', Sigmoid()), ('fc2', Linear(in_features=2, out_features=2, bias=True)), ('s2', Sigmoid())]\n"
     ]
    }
   ],
   "source": [
    "# register hooks on each layer\n",
    "print(list(net._modules.items()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********  Forward Hooks Inputs & Outputs  *********\n",
      "(tensor([0.0500, 0.1000]),)\n",
      "tensor([0.3775, 0.3925], grad_fn=<AddBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.3775, 0.3925], grad_fn=<AddBackward0>),)\n",
      "tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward0>),)\n",
      "tensor([1.1059, 1.2249], grad_fn=<AddBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([1.1059, 1.2249], grad_fn=<AddBackward0>),)\n",
      "tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward0>)\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "*********  Backward Hooks Inputs & Outputs  *********\n",
      "(tensor([0.0392, 0.0435]), tensor([0.0827]))\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "(tensor([0.1625, 0.1806]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.1868, 0.1755]), tensor([0.3623]))\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "(tensor([1., 1.]),)\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceyhun/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "hookF = [Hook(layer[1]) for layer in list(net._modules.items())]\n",
    "hookB = [Hook(layer[1],backward=True) for layer in list(net._modules.items())]\n",
    "# run a data batch\n",
    "out=net(data)\n",
    "# backprop once to get the backward hook results\n",
    "out.backward(torch.tensor([1,1],dtype=torch.float),retain_graph=True)\n",
    "#! loss.backward(retain_graph=True)  # doesn't work with backward hooks,\n",
    "#! since it's not a network layer but an aggregated result from the outputs of last layer vs target\n",
    "\n",
    "print('***'*3+'  Forward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookF:\n",
    "    print(hook.input)\n",
    "    print(hook.output)\n",
    "    print('---'*17)\n",
    "print('\\n')\n",
    "print('***'*3+'  Backward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookB:\n",
    "    print(hook.input)\n",
    "    print(hook.output)\n",
    "    print('---'*17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the input and output of forward and backward pass?\n",
    "Things to notice:\n",
    "Because backward pass runs from back to the start, it's parameter order should be reversed compared to the forward pass. Therefore, to be it clearer, I'll use a different naming convention below.\n",
    "For forward pass, previous layer of layer 2 is layer1; for backward pass, previous layer of layer 2 is layer 3.\n",
    "Model output is the output of last layer in forward pass.\n",
    "layer.register_backward_hook(module, input, output)\n",
    "\n",
    "Input: previous layer's output\n",
    "Output: current layer's output\n",
    "layer.register_backward_hook(module, grad_out, grad_in)\n",
    "\n",
    "#### Grad_in: gradient of model output wrt. layer output       # from forward pass\n",
    "= a tensor that represent the error of each neuron in this layer (= gradient of model output wrt. layer output = how much it should be improved)\n",
    "For the last layer: eg. [1,1] <=> gradient of model output wrt. itself, which means calculate all gradients as normal\n",
    "It can also be considered as a weight map: eg. [1,0] turn off the second gradient; [2,1] put double weight on first gradient etc.\n",
    "#### Grad_out: Grad_in * (gradient of layer output wrt. layer input)\n",
    "= next layer's error(due to chain rule)\n",
    "Check the print from the cell above to confirm and enhance your understanding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.18679804, 0.17552559])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the calculations with the print result above\n",
    "# the 4th layer - sigmoid\n",
    "forward_output = np.array([0.7514, 0.7729])\n",
    "grad_in = np.array([1,1])  # sigmoid layer\n",
    "# grad of sigmoid(x) wrt x is: sigmoid(x)(1-sigmoid(x))\n",
    "grad_out = grad_in*(forward_output*(1-forward_output)); grad_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1868, 0.1755]\n",
      "0.36229999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.18679804, 0.17552559])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 3th layer - linear\n",
    "print([0.1868, 0.1755])  # grad_input * (grad of Wx+b = (w1*x1+w2*x2)+b wrt W)\n",
    "print(0.1868 + 0.1755)   # grad of Wx+b wrt b o\n",
    "\n",
    "grad_in = torch.Tensor(grad_out)\n",
    "grad_in.view(1,-1) @ weight2;grad_out  # grad of layer output wrt input: wx+b => w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.03921046, 0.04345424])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 2nd layer - sigmoid\n",
    "forward_output=np.array([0.5933, 0.5969])\n",
    "grad_in=np.array([0.1625, 0.1806])\n",
    "grad_in*(forward_output*(1-forward_output)) # grad * (grad of sigmoid(x) wrt x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0004, 0.0009],\n",
      "        [0.0005, 0.0010]])\n",
      "tensor([0.0187])\n",
      "tensor([[ 0.0822,  0.0827],\n",
      "        [-0.0226, -0.0227]])\n",
      "tensor([0.1004])\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient of loss wrt parameters\n",
    "net.zero_grad()\n",
    "loss.backward(retain_graph=True)\n",
    "[print(p.grad) for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify gradients with hooks\n",
    "Hook function doesn't change gradients by default\n",
    "But if return is called, the returned value will be the gradient output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guided backpropagation with hooks - Visualize CNN (deconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Guided_backprop():\n",
    "    \"\"\"\n",
    "        Visualize CNN activation maps with guided backprop.\n",
    "\n",
    "        Returns: An image that represent what the network learnt for recognizing\n",
    "        the given image.\n",
    "\n",
    "        Methods: First layer input that minimize the error between the last layers output,\n",
    "        for the given class, and the true label(=1).\n",
    "\n",
    "        ! Call visualize(image) to get the image representation\n",
    "    \"\"\"\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.image_reconstruction = None\n",
    "        self.activation_maps = []\n",
    "        # eval mode\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "\n",
    "    def register_hooks(self):\n",
    "\n",
    "        def first_layer_hook_fn(module, grad_out, grad_in):\n",
    "            \"\"\" Return reconstructed activation image\"\"\"\n",
    "            print('grad_out', grad_out[0])\n",
    "            self.image_reconstruction = grad_out[0]\n",
    "\n",
    "        def forward_hook_fn(module, input, output):\n",
    "            \"\"\" Stores the forward pass outputs (activation maps)\"\"\"\n",
    "            self.activation_maps.append(output)\n",
    "\n",
    "        def backward_hook_fn(module, grad_out, grad_in):\n",
    "            \"\"\" Output the grad of model output wrt. layer (only positive) \"\"\"\n",
    "\n",
    "            # Gradient of forward_output wrt. forward_input = error of activation map:\n",
    "            # for relu layer: grad of zero = 0, grad of identity = 1\n",
    "            grad = self.activation_maps[-1] # corresponding forward pass output\n",
    "            print('grad.shape',grad.shape)\n",
    "            grad[grad>0] = 1 # grad of relu when > 0\n",
    "\n",
    "            # set negative output gradient to 0 #!???\n",
    "            positive_grad_out = torch.clamp(input=grad_out[0],min=0.0)\n",
    "            print('positive_grad_out.shape',positive_grad_out.shape)\n",
    "\n",
    "            # backward grad_out = grad_out * (grad of forward output wrt. forward input)\n",
    "            new_grad_out = positive_grad_out * grad\n",
    "\n",
    "            del self.forward_outputs[-1]\n",
    "\n",
    "            # For hook functions, the returned value will be the new grad_out\n",
    "            return (new_grad_out,)\n",
    "\n",
    "        # !!!!!!!!!!!!!!!! change the modules !!!!!!!!!!!!!!!!!!\n",
    "        # only conv layers, no flattened fc linear layers\n",
    "        modules = list(self.model.features._modules.items())\n",
    "\n",
    "        # register hooks to relu layers\n",
    "        for name, module in modules:\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                module.register_forward_hook(forward_hook_fn)\n",
    "                module.register_backward_hook(backward_hook_fn)\n",
    "\n",
    "        # register hook to the first layer\n",
    "        first_layer = modules[0][1]\n",
    "        first_layer.register_backward_hook(first_layer_hook_fn)\n",
    "\n",
    "    def visualize(self, input_image, target_class):\n",
    "        # last layer output\n",
    "        model_output = self.model(input_image)\n",
    "        print(model_output.shape)\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # only calculate gradients wrt. target class\n",
    "        # set the other classes to 0: eg. [0,0,1]\n",
    "        grad_target_map = torch.zeros(model_output.shape,\n",
    "                                      dtype=torch.float)\n",
    "        grad_target_map[0][target_class] = 0\n",
    "\n",
    "        model_output.backward(grad_target_map)\n",
    "\n",
    "        # Convert Pytorch variable to numpy array\n",
    "        # [0] to get rid of the first channel (1,3,224,224)\n",
    "        result = self.image_reconstruction.data.numpy()[0]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vgg19\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# define a 1 image dataset\n",
    "dataset = datasets.ImageFolder(root='~/PYTORCH/data4/', transform=transform)\n",
    "\n",
    "# define the dataloader to load that single image\n",
    "dataloader = DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#vgg19()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = vgg19()\n",
    "back = Guided_backprop(model=model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 224, 224])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, target = next(iter(dataloader))\n",
    "img.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "back.register_hooks()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceyhun/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n",
      "grad.shape torch.Size([1, 512, 14, 14])\n",
      "positive_grad_out.shape torch.Size([1, 512, 14, 14])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Guided_backprop' object has no attribute 'forward_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisualize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[12], line 79\u001B[0m, in \u001B[0;36mGuided_backprop.visualize\u001B[0;34m(self, input_image, target_class)\u001B[0m\n\u001B[1;32m     75\u001B[0m grad_target_map \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(model_output\u001B[38;5;241m.\u001B[39mshape,\n\u001B[1;32m     76\u001B[0m                               dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[1;32m     77\u001B[0m grad_target_map[\u001B[38;5;241m0\u001B[39m][target_class] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 79\u001B[0m \u001B[43mmodel_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad_target_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;66;03m# Convert Pytorch variable to numpy array\u001B[39;00m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;66;03m# [0] to get rid of the first channel (1,3,224,224)\u001B[39;00m\n\u001B[1;32m     83\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_reconstruction\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mnumpy()[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/_tensor.py:488\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    480\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    481\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    486\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    487\u001B[0m     )\n\u001B[0;32m--> 488\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/nn/modules/module.py:62\u001B[0m, in \u001B[0;36m_WrappedHook.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     61\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to call the hook of a dead Module!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 62\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhook(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "Cell \u001B[0;32mIn[12], line 48\u001B[0m, in \u001B[0;36mGuided_backprop.register_hooks.<locals>.backward_hook_fn\u001B[0;34m(module, grad_out, grad_in)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# backward grad_out = grad_out * (grad of forward output wrt. forward input)\u001B[39;00m\n\u001B[1;32m     46\u001B[0m new_grad_out \u001B[38;5;241m=\u001B[39m positive_grad_out \u001B[38;5;241m*\u001B[39m grad\n\u001B[0;32m---> 48\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_outputs\u001B[49m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# For hook functions, the returned value will be the new grad_out\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (new_grad_out,)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Guided_backprop' object has no attribute 'forward_outputs'"
     ]
    }
   ],
   "source": [
    "back.visualize(img, target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "c = a*b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = torch.tensor(4., requires_grad=True)\n",
    "e = c * d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e.backward()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(a, a.grad)\n",
    "print(b, b.grad)\n",
    "print(d, d.grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "c = a*b\n",
    "\n",
    "def c_hook(grad):\n",
    "    print(grad)\n",
    "    return grad + 2\n",
    "\n",
    "c.register_hook(c_hook)\n",
    "c.register_hook(lambda grad : print(grad))\n",
    "c.retain_grad()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = torch.tensor(4., requires_grad=True)\n",
    "d.register_hook(lambda grad: grad + 100)\n",
    "e = c * d\n",
    "\n",
    "e.retain_grad()\n",
    "e.register_hook(lambda grad: grad * 2)\n",
    "e.retain_grad()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mc\u001B[49m\u001B[38;5;241m.\u001B[39mgrad\n",
      "\u001B[0;31mNameError\u001B[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "c.grad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "inputs (tensor(1., requires_grad=True), tensor(2., requires_grad=True))\n",
      "(tensor(11., grad_fn=<AddBackward0>), tensor(2., requires_grad=True))\n",
      "ssss tensor(16., grad_fn=<AddBackward0>)\n",
      "tensor(1.)\n",
      "d tensor(116., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SumNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SumNet, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(a,b,c):\n",
    "        d =  a+b+c\n",
    "        return d\n",
    "\n",
    "def forward_pre_hook(module, inputs):\n",
    "    print('inputs', inputs)\n",
    "    a,b = inputs\n",
    "    return a + 10, b\n",
    "\n",
    "def forward_hook(module, inputs, outputs):\n",
    "    print(inputs)\n",
    "    print(\"ssss\",outputs)\n",
    "    return outputs + 100\n",
    "\n",
    "def main():\n",
    "    sum_net = SumNet()\n",
    "\n",
    "    sum_net.register_forward_pre_hook(forward_pre_hook)\n",
    "    sum_net.register_forward_hook(forward_hook)\n",
    "\n",
    "    a = torch.tensor(1., requires_grad=True)\n",
    "    b = torch.tensor(2., requires_grad=True)\n",
    "    c = torch.tensor(3., requires_grad=True)\n",
    "    print(a.grad)\n",
    "\n",
    "    d = sum_net(a,b,c=c)\n",
    "    d.backward()\n",
    "    print(a.grad)\n",
    "\n",
    "    print('d', d)\n",
    "\n",
    "main()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module MyMultiply()\n",
      "grad_input (tensor(3.), tensor(1.))\n",
      "grad_output (tensor(1.),)\n",
      "tensor(6.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "class MyMultiply(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMultiply, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(a,b,c):\n",
    "        return (a**b) * c\n",
    "\n",
    "\n",
    "def backward_hook(module, grad_inputsss, grad_outputsss):\n",
    "    print('module', module)\n",
    "    print('grad_input', grad_inputsss)\n",
    "    print('grad_output', grad_outputsss)\n",
    "\n",
    "\n",
    "def main():\n",
    "    my_multiply = MyMultiply()\n",
    "    my_multiply.register_backward_hook(backward_hook)\n",
    "\n",
    "    a = torch.tensor(1., requires_grad=True)\n",
    "    b = torch.tensor(2., requires_grad=True)\n",
    "    c = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "\n",
    "    d = my_multiply(a,b,c=c)\n",
    "\n",
    "    d.backward()\n",
    "    print(a.grad)\n",
    "    print(b.grad)\n",
    "    print(c.grad)\n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7431,  0.6251, -1.1688, -1.1759])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([-0.5000,  0.5600, -0.5000, -0.5000])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4)\n",
    "print(a)\n",
    "\n",
    "torch.clamp(a, min=-0.5, max=0.56)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0000, -0.3333,  0.3333,  1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([-0.7431,  0.6251,  0.3333,  1.0000])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min = torch.linspace(-1, 1, steps=4)\n",
    "print(min)\n",
    "torch.clamp(a, min=min)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
