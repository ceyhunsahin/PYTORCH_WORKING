{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s1): Sigmoid()\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.s1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "        self.s2 = nn.Sigmoid()\n",
    "        self.fc1.weight = torch.nn.Parameter(torch.Tensor([[0.15,0.2],[0.250,0.30]]))\n",
    "        self.fc1.bias = torch.nn.Parameter(torch.Tensor([0.35]))\n",
    "        self.fc2.weight = torch.nn.Parameter(torch.Tensor([[0.4,0.45],[0.5,0.55]]))\n",
    "        self.fc2.bias = torch.nn.Parameter(torch.Tensor([0.6]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.fc1(x)\n",
    "        x = self.s1(x)\n",
    "        x= self.fc2(x)\n",
    "        x = self.s2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.1500, 0.2000],\n",
      "        [0.2500, 0.3000]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3500], requires_grad=True), Parameter containing:\n",
      "tensor([[0.4000, 0.4500],\n",
      "        [0.5000, 0.5500]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6000], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# parameters: weight and bias\n",
    "print(list(net.parameters()))\n",
    "# input data\n",
    "weight2 = list(net.parameters())[2]\n",
    "data = torch.Tensor([0.05,0.1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.2984, grad_fn=<MseLossBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of last layer\n",
    "out = net(data)\n",
    "target = torch.Tensor([0.01,0.99])  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target); loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# A simple hook class that returns the input and output of a layer during forward/backward pass\n",
    "class Hook():\n",
    "    def __init__(self, module, backward=False):\n",
    "        if backward==False:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********  Forward Hooks Inputs & Outputs  *********\n",
      "(tensor([0.0500, 0.1000]),)\n",
      "tensor([0.3775, 0.3925], grad_fn=<AddBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.3775, 0.3925], grad_fn=<AddBackward0>),)\n",
      "tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward0>),)\n",
      "tensor([1.1059, 1.2249], grad_fn=<AddBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([1.1059, 1.2249], grad_fn=<AddBackward0>),)\n",
      "tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward0>)\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "*********  Backward Hooks Inputs & Outputs  *********\n",
      "(tensor([0.0392, 0.0435]), tensor([0.0827]))\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "(tensor([0.1625, 0.1806]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.1868, 0.1755]), tensor([0.3623]))\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "(tensor([1., 1.]),)\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceyhun/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "# register hooks on each layer\n",
    "hookF = [Hook(layer[1]) for layer in list(net._modules.items())]\n",
    "hookB = [Hook(layer[1],backward=True) for layer in list(net._modules.items())]\n",
    "# run a data batch\n",
    "out=net(data)\n",
    "# backprop once to get the backward hook results\n",
    "out.backward(torch.tensor([1,1],dtype=torch.float),retain_graph=True)\n",
    "#! loss.backward(retain_graph=True)  # doesn't work with backward hooks,\n",
    "#! since it's not a network layer but an aggregated result from the outputs of last layer vs target\n",
    "\n",
    "print('***'*3+'  Forward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookF:\n",
    "    print(hook.input)\n",
    "    print(hook.output)\n",
    "    print('---'*17)\n",
    "print('\\n')\n",
    "print('***'*3+'  Backward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookB:\n",
    "    print(hook.input)\n",
    "    print(hook.output)\n",
    "    print('---'*17)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the input and output of forward and backward pass?\n",
    "Things to notice:\n",
    "Because backward pass runs from back to the start, it's parameter order should be reversed compared to the forward pass. Therefore, to be it clearer, I'll use a different naming convention below.\n",
    "For forward pass, previous layer of layer 2 is layer1; for backward pass, previous layer of layer 2 is layer 3.\n",
    "Model output is the output of last layer in forward pass.\n",
    "layer.register_backward_hook(module, input, output)\n",
    "\n",
    "Input: previous layer's output\n",
    "Output: current layer's output\n",
    "layer.register_backward_hook(module, grad_out, grad_in)\n",
    "\n",
    "Grad_in: gradient of model output wrt. layer output       # from forward pass\n",
    "= a tensor that represent the error of each neuron in this layer (= gradient of model output wrt. layer output = how much it should be improved)\n",
    "For the last layer: eg. [1,1] <=> gradient of model output wrt. itself, which means calculate all gradients as normal\n",
    "It can also be considered as a weight map: eg. [1,0] turn off the second gradient; [2,1] put double weight on first gradient etc.\n",
    "Grad_out: Grad_in * (gradient of layer output wrt. layer input)\n",
    "= next layer's error(due to chain rule)\n",
    "Check the print from the cell above to confirm and enhance your understanding!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.18679804, 0.17552559])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the calculations with the print result above\n",
    "# the 4th layer - sigmoid\n",
    "forward_output = np.array([0.7514, 0.7729])\n",
    "grad_in = np.array([1,1])  # sigmoid layer\n",
    "# grad of sigmoid(x) wrt x is: sigmoid(x)(1-sigmoid(x))\n",
    "grad_out = grad_in*(forward_output*(1-forward_output)); grad_out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1868, 0.1755]\n",
      "0.36229999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.18679804, 0.17552559])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 3th layer - linear\n",
    "print([0.1868, 0.1755])  # grad_input * (grad of Wx+b = (w1*x1+w2*x2)+b wrt W)\n",
    "print(0.1868 + 0.1755)   # grad of Wx+b wrt b o\n",
    "\n",
    "grad_in = torch.Tensor(grad_out)\n",
    "grad_in.view(1,-1) @ weight2;grad_out  # grad of layer output wrt input: wx+b => w\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.03921046, 0.04345424])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 2nd layer - sigmoid\n",
    "forward_output=np.array([0.5933, 0.5969])\n",
    "grad_in=np.array([0.1625, 0.1806])\n",
    "grad_in*(forward_output*(1-forward_output)) # grad * (grad of sigmoid(x) wrt x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0004, 0.0009],\n",
      "        [0.0005, 0.0010]])\n",
      "tensor([0.0187])\n",
      "tensor([[ 0.0822,  0.0827],\n",
      "        [-0.0226, -0.0227]])\n",
      "tensor([0.1004])\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient of loss wrt prarameters\n",
    "net.zero_grad()\n",
    "loss.backward(retain_graph=True)\n",
    "[print(p.grad) for p in net.parameters()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modify gradients with hooks\n",
    "Hook function doesn't change gradients by default\n",
    "But if return is called, the returned value will be the gradient output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Guided backpropagation with hooks - Visualize CNN (deconv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Guided_backprop():\n",
    "    \"\"\"\n",
    "        Visualize CNN activation maps with guided backprop.\n",
    "\n",
    "        Returns: An image that represent what the network learnt for recognizing\n",
    "        the given image.\n",
    "\n",
    "        Methods: First layer input that minimize the error between the last layers output,\n",
    "        for the given class, and the true label(=1).\n",
    "\n",
    "        ! Call visualize(image) to get the image representation\n",
    "    \"\"\"\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.image_reconstruction = None\n",
    "        self.activation_maps = []\n",
    "        # eval mode\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "\n",
    "    def register_hooks(self):\n",
    "\n",
    "        def first_layer_hook_fn(module, grad_out, grad_in):\n",
    "            \"\"\" Return reconstructed activation image\"\"\"\n",
    "            self.image_reconstruction = grad_out[0]\n",
    "\n",
    "        def forward_hook_fn(module, input, output):\n",
    "            \"\"\" Stores the forward pass outputs (activation maps)\"\"\"\n",
    "            self.activation_maps.append(output)\n",
    "\n",
    "        def backward_hook_fn(module, grad_out, grad_in):\n",
    "            \"\"\" Output the grad of model output wrt. layer (only positive) \"\"\"\n",
    "\n",
    "            # Gradient of forward_output wrt. forward_input = error of activation map:\n",
    "            # for relu layer: grad of zero = 0, grad of identity = 1\n",
    "            grad = self.activation_maps[-1] # corresponding forward pass output\n",
    "            grad[grad>0] = 1 # grad of relu when > 0\n",
    "\n",
    "            # set negative output gradient to 0 #!???\n",
    "            positive_grad_out = torch.clamp(input=grad_out[0],min=0.0)\n",
    "\n",
    "            # backward grad_out = grad_out * (grad of forward output wrt. forward input)\n",
    "            new_grad_out = positive_grad_out * grad\n",
    "\n",
    "            del self.forward_outputs[-1]\n",
    "\n",
    "            # For hook functions, the returned value will be the new grad_out\n",
    "            return (new_grad_out,)\n",
    "\n",
    "        # !!!!!!!!!!!!!!!! change the modules !!!!!!!!!!!!!!!!!!\n",
    "        # only conv layers, no flattened fc linear layers\n",
    "        modules = list(self.model.features._modules.items())\n",
    "\n",
    "        # register hooks to relu layers\n",
    "        for name, module in modules:\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                module.register_forward_hook(forward_hook_fn)\n",
    "                module.register_backward_hook(backward_hook_fn)\n",
    "\n",
    "        # register hook to the first layer\n",
    "        first_layer = modules[0][1]\n",
    "        first_layer.register_backward_hook(first_layer_hook_fn)\n",
    "\n",
    "    def visualize(self, input_image, target_class):\n",
    "        # last layer output\n",
    "        model_output = self.model(input_image)\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # only calculate gradients wrt. target class\n",
    "        # set the other classes to 0: eg. [0,0,1]\n",
    "        grad_target_map = torch.zeros(model_output.shape,\n",
    "                                      dtype=torch.float)\n",
    "        grad_target_map[0][target_class] = 1\n",
    "\n",
    "        model_output.backward(grad_target_map)\n",
    "\n",
    "        # Convert Pytorch variable to numpy array\n",
    "        # [0] to get rid of the first channel (1,3,224,224)\n",
    "        result = self.image_reconstruction.data.numpy()[0]\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
