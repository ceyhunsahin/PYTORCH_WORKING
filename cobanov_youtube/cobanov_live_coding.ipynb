{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def prep_dataset(folder_path):\n",
    "    transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),\n",
    "\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                    ])\n",
    "\n",
    "    # define an image dataset\n",
    "\n",
    "    image_dataset = datasets.ImageFolder(root=folder_path, transform=transform)\n",
    "\n",
    "    dataloader = data.DataLoader(dataset=image_dataset, shuffle=False, batch_size=8)\n",
    "\n",
    "    return dataloader, image_dataset\n",
    "\n",
    "def save_embeddings(output_path, embeddings, filelist):\n",
    "\n",
    "    np.savez('./embeddings.npz', embedding = embeddings, filelist= filelist)\n",
    "\n",
    "\n",
    "def calculate_embeddings(model, dataloader):\n",
    "    feature_embeddings = []\n",
    "    from tqdm import tqdm\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm(dataloader):\n",
    "            embedding = model(image)\n",
    "            feature_embeddings.extend(embedding.numpy())\n",
    "    np_embeddings = np.vstack(feature_embeddings)\n",
    "    print(np_embeddings.shape)\n",
    "    return np_embeddings\n",
    "\n",
    "def calculate_pca(embeddings, k = 16):\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=k)\n",
    "    pca_embeddings = pca.fit_transform(embeddings)\n",
    "    return pca_embeddings\n",
    "\n",
    "def find_clusters(pca_embeddings, k = 10):\n",
    "    from scipy.cluster.vq import kmeans2\n",
    "    centroid, label = kmeans2(pca_embeddings,k, minit = 'points')\n",
    "    return centroid, label\n",
    "\n",
    "def copy_to_clusters(label, filelist):\n",
    "    for label_number in range(len(np.bincount(label))) :\n",
    "        label_mask = label_number == label\n",
    "    cluster_images = list(itertools.compress(filelist, label_mask))\n",
    "    for img_path in cluster_images:\n",
    "        Path(f'./output/{label_number}').mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(img_path, f'./output/{label_number}/{img_path.split(\"/\")[-1]}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_images_from_directory(image_directory: str) -> list :\n",
    "    \"\"\"\n",
    "    > It takes a directory as input and returns a list of all the images in that directory\n",
    "    :param image_directory: The directory where the images are stored\n",
    "    :return: Alist of images\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_images = list()\n",
    "    for ext in (\"*.gif\", \"*.png\", \"*.jpg\", \"*.jpeg\"):\n",
    "        list_of_images.extend(\n",
    "            glob.glob(os.path.join(image_directory, ext))\n",
    "        )\n",
    "    print(f\"images found : {len(list_of_images)}\")\n",
    "    return list_of_images\n",
    "\n",
    "def read_with_pil(list_of_images: list, resize = False) -> list :\n",
    "    pil_images = list()\n",
    "    for img_path in list_of_images:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if resize:\n",
    "            img.thumbnail((512,512))\n",
    "        pil_images.append(img)\n",
    "    return pil_images\n",
    "\n",
    "def main():\n",
    "    CLUSTER_RANGE = 16\n",
    "    import torch\n",
    "    print(torch.cuda.is_available())\n",
    "\n",
    "    print('model')\n",
    "\n",
    "    model = timm.create_model('resnet34', pretrained=True)\n",
    "    print('model2')\n",
    "\n",
    "    #list_of_images = read_images_from_directory('./images/')\n",
    "    #pil_images = read_with_pil(list_of_images, resize = False)\n",
    "    dataloader, image_dataset = prep_dataset('./root')\n",
    "\n",
    "    filelist = [path for path, label in image_dataset.imgs]\n",
    "\n",
    "    print('ceyhun1')\n",
    "    feature_embeddings = calculate_embeddings(model, dataloader)\n",
    "    print('ceyhun')\n",
    "\n",
    "    save_embeddings('./embeddings.npz', feature_embeddings, filelist)\n",
    "\n",
    "    pca_embeddings = calculate_pca(feature_embeddings)\n",
    "    cluster, label = find_clusters(pca_embeddings, k= CLUSTER_RANGE)\n",
    "    print('avant final')\n",
    "    copy_to_clusters(label, filelist)\n",
    "    print('final')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "model\n",
      "model2\n",
      "ceyhun1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:02<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2046, 1000)\n",
      "ceyhun\n",
      "avant final\n",
      "final\n"
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
