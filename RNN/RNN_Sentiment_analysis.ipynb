{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "import torchdata\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_dataset = IMDB(split='train')\n",
    "test_dataset = IMDB(split='test')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "## Step 1: create the datasets\n",
    "from torch.utils.data.dataset import random_split\n",
    "torch.manual_seed(1)\n",
    "\n",
    "train_dataset, valid_dataset = random_split(list(train_dataset), [20000, 5000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(1,\n 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clich√©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = next(iter(test_dataset))\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(2,\n 'An extra is called upon to play a general in a movie about the Russian Revolution. However, he is not any ordinary extra. He is Serguis Alexander, former commanding general of the Russia armies who is now being forced to relive the same scene, which he suffered professional and personal tragedy in, to satisfy the director who was once a revolutionist in Russia and was humiliated by Alexander. It can now be the time for this broken man to finally \"win\" his penultimate battle. This is one powerful movie with meticulous direction by Von Sternberg, providing the greatest irony in Alexander\\'s character in every way he can. Jannings deserved his Oscar for the role with a very moving performance playing the general at his peak and at his deepest valley. Powell lends a sinister support as the revenge minded director and Brent is perfect in her role with her face and movements showing so much expression as Jannings\\' love. All around brilliance. Rating, 10.')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = next(iter(train_dataset))\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# we will first find the unique words (tokens) in the training dataset\n",
    "## Step 2: find unique tokens (words)\n",
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "token_counts = Counter()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for label, line in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 69023\n"
     ]
    }
   ],
   "source": [
    "print('Vocab-size:', len(token_counts))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'an': 17204,\n         'extra': 244,\n         'is': 85847,\n         'called': 1140,\n         'upon': 675,\n         'to': 107513,\n         'play': 1752,\n         'a': 130057,\n         'general': 619,\n         'in': 74646,\n         'movie': 35149,\n         'about': 13734,\n         'the': 267877,\n         'russian': 250,\n         'revolution': 160,\n         'however': 2892,\n         'he': 24075,\n         'not': 24329,\n         'any': 6089,\n         'ordinary': 222,\n         'serguis': 2,\n         'alexander': 100,\n         'former': 416,\n         'commanding': 37,\n         'of': 116119,\n         'russia': 66,\n         'armies': 17,\n         'who': 17112,\n         'now': 3704,\n         'being': 5224,\n         'forced': 505,\n         'relive': 19,\n         'same': 3244,\n         'scene': 4223,\n         'which': 9563,\n         'suffered': 116,\n         'professional': 270,\n         'and': 130797,\n         'personal': 510,\n         'tragedy': 291,\n         'satisfy': 73,\n         'director': 3578,\n         'was': 38365,\n         'once': 1886,\n         'revolutionist': 1,\n         'humiliated': 23,\n         'by': 17895,\n         'it': 76964,\n         'can': 11688,\n         'be': 21260,\n         'time': 10042,\n         'for': 35262,\n         'this': 60714,\n         'broken': 220,\n         'man': 4785,\n         'finally': 1216,\n         'win': 373,\n         'his': 23434,\n         'penultimate': 13,\n         'battle': 505,\n         'one': 21383,\n         'powerful': 503,\n         'with': 35163,\n         'meticulous': 11,\n         'direction': 1101,\n         'von': 159,\n         'sternberg': 12,\n         'providing': 95,\n         'greatest': 578,\n         'irony': 116,\n         's': 50537,\n         'character': 5485,\n         'every': 3189,\n         'way': 6428,\n         'jannings': 23,\n         'deserved': 235,\n         'oscar': 690,\n         'role': 2506,\n         'very': 11229,\n         'moving': 675,\n         'performance': 2298,\n         'playing': 1290,\n         'at': 18751,\n         'peak': 62,\n         'deepest': 39,\n         'valley': 64,\n         'powell': 160,\n         'lends': 47,\n         'sinister': 133,\n         'support': 292,\n         'as': 37322,\n         'revenge': 436,\n         'minded': 133,\n         'brent': 41,\n         'perfect': 1249,\n         'her': 14693,\n         'face': 1298,\n         'movements': 89,\n         'showing': 603,\n         'so': 16433,\n         'much': 7754,\n         'expression': 134,\n         'love': 5165,\n         'all': 19102,\n         'around': 2848,\n         'brilliance': 102,\n         'rating': 740,\n         '10': 3438,\n         'almost': 2530,\n         'review': 674,\n         'i': 69938,\n         'd': 2395,\n         'seen': 5267,\n         'pretty': 2968,\n         'bad': 7323,\n         'actually': 3371,\n         'good': 12158,\n         'though': 3679,\n         'great': 7223,\n         'judy': 86,\n         'garland': 52,\n         'could': 6298,\n         'have': 21941,\n         'gotten': 223,\n         'annoying': 808,\n         'but': 34034,\n         'she': 11390,\n         'didn': 3460,\n         't': 27384,\n         'allow': 251,\n         'somewhere': 385,\n         'along': 1407,\n         'line': 1464,\n         've': 4089,\n         'become': 1222,\n         'fan': 1530,\n         'brooding': 51,\n         'overbearing': 40,\n         'overacting': 65,\n         'van': 376,\n         'heflin': 21,\n         'least': 2512,\n         'early': 1256,\n         '40': 312,\n         'singing': 417,\n         'film': 32139,\n         'missed': 459,\n         'chance': 857,\n         'more': 11196,\n         'their': 8924,\n         'relationship': 752,\n         'gave': 998,\n         '7': 740,\n         'did': 5030,\n         'too': 6221,\n         'interest': 824,\n         'watching': 3702,\n         'flock': 38,\n         'andrew': 124,\n         'lau': 13,\n         'co': 463,\n         'directed': 959,\n         'masterpiece': 479,\n         'trilogy': 173,\n         'infernal': 10,\n         'affairs': 58,\n         'had': 9009,\n         'been': 7414,\n         'fired': 103,\n         'from': 16269,\n         'replaced': 129,\n         'emergency': 21,\n         'niels': 3,\n         'mueller': 5,\n         'feeling': 886,\n         'that': 58340,\n         'made': 6698,\n         'satisfied': 81,\n         'study': 191,\n         'they': 18203,\n         'him': 7123,\n         'hired': 153,\n         'another': 3468,\n         'usually': 772,\n         'does': 4699,\n         'work': 3519,\n         'well': 8476,\n         'let': 1838,\n         'remember': 1370,\n         'invasion': 69,\n         'resulted': 43,\n         'better': 4588,\n         'than': 7871,\n         'what': 12793,\n         'expected': 540,\n         'interesting': 2522,\n         'entertaining': 1192,\n         'thriller': 692,\n         'development': 506,\n         'done': 2417,\n         'know': 4899,\n         'characters': 5648,\n         'also': 7271,\n         'between': 2664,\n         'two': 5498,\n         'main': 1788,\n         'natural': 381,\n         'credible': 124,\n         'richard': 694,\n         'gere': 54,\n         'claire': 131,\n         'danes': 87,\n         'bring': 696,\n         'competent': 110,\n         'performances': 1465,\n         'go': 4097,\n         'negative': 291,\n         'points': 651,\n         'element': 313,\n         'really': 9441,\n         'bothered': 150,\n         'me': 8562,\n         'there': 15079,\n         'moment': 899,\n         'irritated': 34,\n         'excess': 55,\n         'edition': 68,\n         'tricks': 120,\n         'give': 2651,\n         'attitude': 198,\n         'style': 1269,\n         'feel': 2341,\n         'out': 13642,\n         'place': 1923,\n         'presence': 316,\n         'arbitrary': 25,\n         'plus': 508,\n         'think': 5831,\n         'should': 3975,\n         'ambitious': 92,\n         'spite': 142,\n         'recommend': 1351,\n         'memorable': 538,\n         'ulises': 8,\n         'literature': 70,\n         'teacher': 256,\n         'arrives': 125,\n         'coastal': 14,\n         'town': 1006,\n         'will': 7352,\n         'fell': 272,\n         'martina': 6,\n         'most': 6950,\n         'beautiful': 1749,\n         'girl': 2301,\n         'start': 1358,\n         'torrid': 10,\n         'romance': 568,\n         'end': 4447,\n         'tragic': 273,\n         'death': 1511,\n         'sea': 210,\n         'some': 12521,\n         'years': 3565,\n         'later': 1749,\n         'has': 13394,\n         'married': 483,\n         'sierra': 23,\n         'richest': 8,\n         'lives': 1130,\n         'quiet': 226,\n         'happy': 776,\n         'live': 1254,\n         'surrounded': 106,\n         'money': 1873,\n         'day': 2231,\n         'apparition': 7,\n         'make': 6382,\n         'passion': 229,\n         'rise': 195,\n         'up': 10557,\n         'act': 1011,\n         'without': 2553,\n         'thinking': 938,\n         'consequences': 103,\n         'plot': 5216,\n         'quite': 2982,\n         'absurd': 233,\n         'none': 814,\n         'actors': 3575,\n         'plays': 1780,\n         'decent': 913,\n         'part': 3208,\n         'addition': 278,\n         'three': 1820,\n         'quarters': 24,\n         'are': 23613,\n         'sexual': 576,\n         'acts': 319,\n         'still': 4529,\n         'filmed': 585,\n         'tiring': 17,\n         'we': 8675,\n         'want': 2932,\n         'see': 9135,\n         'story': 9488,\n         'just': 14054,\n         'bigas': 5,\n         'luna': 11,\n         'lots': 607,\n         'sex': 1297,\n         'no': 10018,\n         'argument': 87,\n         'stupid': 1379,\n         'everywhere': 151,\n         'found': 2030,\n         'fbi': 127,\n         'considerably': 51,\n         'suitably': 59,\n         'upbeat': 34,\n         'my': 10011,\n         'new': 3478,\n         'holiday': 106,\n         'viewing': 603,\n         'its': 6503,\n         'drama': 1130,\n         'action': 2690,\n         'packed': 122,\n         'episodes': 757,\n         'were': 8619,\n         'thrilling': 117,\n         'hardesty': 11,\n         'drawn': 346,\n         'admirable': 58,\n         'overall': 1141,\n         'photography': 327,\n         'script': 2405,\n         'perfectly': 521,\n         'creditable': 5,\n         'rather': 2157,\n         'taking': 735,\n         'repugnant': 17,\n         'piece': 1226,\n         'propaganda': 155,\n         'might': 2320,\n         'enjoyed': 1007,\n         'mounted': 14,\n         'portrayal': 406,\n         'necessity': 40,\n         'ingenious': 57,\n         'minds': 141,\n         'brave': 155,\n         'bodies': 178,\n         'fight': 929,\n         'against': 1199,\n         'crime': 566,\n         'again': 3197,\n         'depiction': 133,\n         'family': 2623,\n         'holding': 173,\n         'together': 1773,\n         'even': 10043,\n         'under': 1076,\n         'strain': 32,\n         'husband': 819,\n         'commitment': 41,\n         'arguably': 71,\n         'important': 732,\n         'find': 3299,\n         'twee': 5,\n         'representation': 60,\n         'ideal': 78,\n         'exemplary': 13,\n         'dumb': 489,\n         'fun': 2219,\n         'cool': 785,\n         'looking': 1972,\n         'aliens': 153,\n         'country': 754,\n         'setting': 513,\n         'isn': 2552,\n         'hear': 581,\n         'broadcast': 92,\n         'war': 1659,\n         'worlds': 106,\n         'when': 11275,\n         'small': 1282,\n         'radio': 201,\n         'station': 258,\n         'on': 27246,\n         'halloween': 205,\n         'come': 2557,\n         'earth': 742,\n         'kill': 975,\n         'humans': 239,\n         'instead': 1775,\n         'killing': 553,\n         'people': 7290,\n         'slaves': 36,\n         'goofy': 132,\n         'front': 489,\n         'cover': 408,\n         'shows': 1849,\n         'these': 4244,\n         'riding': 120,\n         'surfboards': 3,\n         'space': 590,\n         'do': 7282,\n         'aren': 714,\n         'party': 427,\n         'cartoonish': 54,\n         'idiots': 90,\n         'high': 1707,\n         'pitched': 34,\n         'modulated': 5,\n         'voices': 172,\n         'alien': 291,\n         'tolerable': 49,\n         'voice': 893,\n         'happens': 842,\n         'jack': 764,\n         'nicholson': 92,\n         'rip': 266,\n         'off': 4809,\n         'always': 2586,\n         'wears': 134,\n         'sunglasses': 13,\n         'other': 7296,\n         'acting': 5172,\n         'terrible': 1305,\n         'writing': 1025,\n         'obviously': 914,\n         'meant': 487,\n         'children': 1211,\n         'because': 7225,\n         'written': 1278,\n         'like': 16198,\n         'kid': 968,\n         'only': 9470,\n         'appreciate': 410,\n         'maybe': 1829,\n         '1': 1726,\n         '2': 2324,\n         '100': 356,\n         'mins': 43,\n         'pg': 119,\n         'mild': 108,\n         'language': 415,\n         'douglas': 245,\n         'sirk': 74,\n         'said': 1779,\n         'short': 1462,\n         'distance': 93,\n         'art': 1007,\n         'trash': 411,\n         'contains': 328,\n         'craziness': 21,\n         'quality': 1014,\n         'nearer': 10,\n         'statement': 143,\n         'defines': 25,\n         'cinema': 1178,\n         'unique': 505,\n         'body': 795,\n         'includes': 261,\n         'classic': 1470,\n         'stage': 550,\n         'adaptations': 58,\n         'adventure': 393,\n         'films': 5524,\n         'westerns': 115,\n         'course': 2003,\n         'famous': 610,\n         'melodramas': 16,\n         'word': 724,\n         'signifies': 5,\n         'dramas': 113,\n         'music': 2411,\n         'sets': 689,\n         'tone': 395,\n         'masterful': 70,\n         'stroke': 45,\n         'brush': 31,\n         'painter': 52,\n         'leaves': 556,\n         'image': 291,\n         'screen': 1952,\n         'turned': 721,\n         'canvas': 24,\n         'ain': 147,\n         'life': 5270,\n         'imitation': 68,\n         'never': 5070,\n         'tried': 619,\n         'show': 5060,\n         'reality': 769,\n         'contrary': 94,\n         'directors': 506,\n         'generation': 191,\n         'use': 1439,\n         'technical': 231,\n         'devices': 59,\n         'provided': 156,\n         'hollywood': 1470,\n         'notably': 102,\n         'technicolor': 63,\n         'distinguish': 23,\n         'artificial': 74,\n         'real': 3817,\n         'thing': 3646,\n         'golden': 207,\n         'period': 609,\n         'coincides': 6,\n         'attention': 719,\n         'into': 7194,\n         'social': 491,\n         'blackboard': 19,\n         'jungle': 157,\n         'rebel': 81,\n         'cause': 437,\n         'knew': 722,\n         'something': 4114,\n         'else': 1610,\n         'statements': 43,\n         'summarizes': 5,\n         'you': 27236,\n         'reach': 186,\n         'or': 14307,\n         'touch': 373,\n         'reflections': 20,\n         'if': 13335,\n         'try': 1450,\n         'grasp': 75,\n         'happiness': 153,\n         'itself': 1241,\n         'your': 4558,\n         'fingers': 61,\n         'meet': 530,\n         'glass': 131,\n         'defy': 29,\n         'anybody': 254,\n         'wind': 216,\n         'count': 281,\n         'amount': 385,\n         'mirrors': 53,\n         'images': 373,\n         'reflected': 36,\n         'appear': 490,\n         'ends': 772,\n         'giving': 670,\n         'therefore': 263,\n         'hall': 187,\n         'full': 1421,\n         'where': 5173,\n         'difference': 299,\n         'false': 150,\n         'copy': 435,\n         'nobody': 360,\n         'say': 4239,\n         'hadley': 44,\n         'either': 1469,\n         'those': 3739,\n         'hideous': 72,\n         'oil': 116,\n         'pumps': 7,\n         'over': 5066,\n         'realm': 57,\n         'affected': 94,\n         'decore': 1,\n         'fake': 377,\n         'trick': 136,\n         'visible': 69,\n         'everything': 1818,\n         'pushed': 99,\n         'little': 5141,\n         'bit': 2438,\n         'limit': 61,\n         'connotations': 6,\n         'dorothy': 114,\n         'malone': 64,\n         'tower': 49,\n         'example': 1113,\n         'criticizing': 20,\n         'theorizing': 2,\n         'angles': 155,\n         'thoughts': 171,\n         'lighting': 296,\n         'philosophy': 91,\n         'follow': 620,\n         'fall': 602,\n         'traditional': 216,\n         'both': 2716,\n         'geometrical': 6,\n         'terms': 337,\n         'light': 766,\n         'shadows': 88,\n         'hadleys': 1,\n         'house': 1733,\n         'different': 1897,\n         'levels': 186,\n         'connected': 114,\n         'spiral': 35,\n         'staircase': 25,\n         'operates': 21,\n         'strictly': 102,\n         'metaphorical': 13,\n         'resembles': 94,\n         'mausoleum': 3,\n         'cheer': 49,\n         'progresses': 69,\n         'luminous': 18,\n         'daylight': 41,\n         'shadowy': 24,\n         'night': 1719,\n         'becomes': 1134,\n         'extension': 23,\n         'inner': 158,\n         'state': 417,\n         'colours': 51,\n         'clothes': 258,\n         'wear': 145,\n         'thus': 348,\n         'incorporated': 19,\n         'service': 160,\n         'craft': 88,\n         'considered': 391,\n         'himself': 1719,\n         'bender': 16,\n         'bended': 3,\n         'standard': 371,\n         'material': 611,\n         'assigned': 66,\n         'purpose': 354,\n         'wouldn': 845,\n         'hands': 515,\n         'using': 633,\n         'similar': 680,\n         'strategies': 7,\n         'frank': 356,\n         'tashlin': 1,\n         '50': 390,\n         'comedy': 2612,\n         'melodrama': 153,\n         'machinery': 19,\n         'american': 1778,\n         'advertising': 68,\n         'tv': 2184,\n         'jukeboxes': 2,\n         'washing': 26,\n         'machines': 88,\n         'sport': 87,\n         'cars': 222,\n         'vacuum': 15,\n         'cleaners': 6,\n         'depict': 50,\n         'emptiness': 22,\n         'decay': 21,\n         'm': 4027,\n         'inclined': 33,\n         'regarded': 63,\n         'contemporary': 168,\n         'audiences': 379,\n         'game': 1001,\n         'played': 2019,\n         'sides': 122,\n         'camp': 397,\n         'regard': 123,\n         'them': 6277,\n         'cult': 381,\n         'bizarre': 411,\n         'spectators': 14,\n         'anymore': 255,\n         'why': 4188,\n         'todd': 88,\n         'haynes': 3,\n         'homage': 98,\n         'far': 2351,\n         'heaven': 245,\n         'turns': 1012,\n         'pastiche': 20,\n         'reproduces': 2,\n         'nowadays': 136,\n         'nothing': 3394,\n         'happened': 850,\n         'then': 6492,\n         'exactly': 795,\n         'painting': 108,\n         'hanging': 173,\n         'gallery': 44,\n         'julianne': 5,\n         'moore': 176,\n         'gardener': 26,\n         'discuss': 82,\n         'aforementioned': 100,\n         'understood': 140,\n         'elements': 643,\n         'immovable': 1,\n         'rock': 697,\n         'hudson': 112,\n         'lauren': 50,\n         'bacall': 72,\n         'here': 4596,\n         'assemble': 9,\n         'series': 2718,\n         'split': 115,\n         'ones': 745,\n         'balance': 132,\n         'through': 3912,\n         'antithesis': 14,\n         'remarkable': 240,\n         'surprisingly': 357,\n         'root': 100,\n         'interested': 515,\n         'robert': 722,\n         'stack': 65,\n         'flies': 83,\n         'plane': 265,\n         'tempts': 6,\n         'sorts': 149,\n         'mundane': 71,\n         'comforts': 15,\n         'world': 3085,\n         'below': 206,\n         'obvious': 839,\n         'faustian': 3,\n         'echoes': 27,\n         'strangely': 134,\n         'fascinated': 68,\n         'devilish': 19,\n         'nymphomaniac': 14,\n         'sister': 652,\n         'painfully': 189,\n         'evokes': 38,\n         'past': 992,\n         'mitch': 53,\n         'alone': 842,\n         'river': 226,\n         'universe': 147,\n         'studio': 398,\n         'often': 1241,\n         'imposed': 23,\n         'impact': 300,\n         'fact': 2779,\n         'worked': 490,\n         'fond': 82,\n         'greek': 100,\n         'endings': 81,\n         'deux': 10,\n         'ex': 370,\n         'machinea': 1,\n         'final': 1078,\n         'courtroom': 46,\n         'fits': 167,\n         'must': 2582,\n         'whole': 2462,\n         'told': 806,\n         'flashback': 155,\n         'beginning': 1117,\n         'nevertheless': 183,\n         'feud': 12,\n         'pointed': 111,\n         'many': 5313,\n         'similarities': 77,\n         'godfather': 111,\n         'saga': 81,\n         'absolutely': 1203,\n         'agree': 450,\n         'sure': 2147,\n         'parallel': 69,\n         'incidental': 36,\n         'share': 277,\n         'theme': 651,\n         'old': 3677,\n         'father': 1690,\n         'head': 1261,\n         'trying': 1943,\n         'keep': 1293,\n         'empire': 99,\n         'going': 3247,\n         'while': 4231,\n         'protecting': 30,\n         'temperamental': 7,\n         'son': 1084,\n         'portrayed': 489,\n         'amazing': 1050,\n         'physical': 238,\n         'resemblance': 81,\n         'jimmy': 215,\n         'caan': 16,\n         'sonny': 40,\n         'corleone': 32,\n         'fighting': 494,\n         'male': 536,\n         'friend': 1155,\n         'symmetrical': 2,\n         'non': 730,\n         'put': 1908,\n         'trust': 260,\n         'common': 417,\n         'families': 195,\n         'carry': 252,\n         'names': 314,\n         'details': 336,\n         'gate': 54,\n         'gives': 1280,\n         'access': 77,\n         'property': 72,\n         'surroundings': 39,\n         'covered': 162,\n         'suggest': 301,\n         'coppola': 33,\n         'mind': 1588,\n         'masterwork': 18,\n         'deal': 567,\n         'subject': 574,\n         'power': 765,\n         'acquisition': 2,\n         'manipulation': 34,\n         'legacy': 62,\n         'kyle': 83,\n         'sterility': 3,\n         'event': 299,\n         'hastens': 1,\n         'turmoil': 43,\n         'issue': 224,\n         'easily': 710,\n         'tied': 120,\n         'central': 323,\n         'case': 1223,\n         'weakness': 60,\n         'deals': 210,\n         'uses': 433,\n         'citizen': 101,\n         'kane': 98,\n         'first': 7231,\n         'welles': 167,\n         'starting': 216,\n         'petrol': 8,\n         'business': 478,\n         'origin': 47,\n         'fortune': 122,\n         'ending': 1850,\n         'wayne': 178,\n         'charles': 312,\n         'foster': 136,\n         'adopted': 59,\n         'tutor': 10,\n         'having': 2021,\n         'own': 2653,\n         'alive': 377,\n         'amazingly': 142,\n         'actor': 1886,\n         'harry': 360,\n         'shannon': 32,\n         'perform': 119,\n         'fathers': 63,\n         'detail': 262,\n         'cannot': 852,\n         'coincidence': 64,\n         'aspect': 353,\n         'execution': 156,\n         'vision': 242,\n         'technique': 121,\n         'highlight': 161,\n         'career': 809,\n         'wonderful': 1349,\n         'best': 5105,\n         'opinion': 754,\n         'magnificent': 211,\n         'obsession': 134,\n         'allows': 198,\n         'tomorrow': 62,\n         'level': 755,\n         'dallas': 35,\n         'dinasty': 1,\n         'wish': 778,\n         'n64': 11,\n         'bowser': 9,\n         'usual': 778,\n         'shenanigans': 22,\n         'yeah': 383,\n         'mario': 81,\n         'stop': 878,\n         'nostalgia': 68,\n         'graphics': 139,\n         'awful': 1356,\n         'today': 1004,\n         'standards': 284,\n         'especially': 2031,\n         'mini': 166,\n         'games': 271,\n         'unlock': 11,\n         'second': 1587,\n         'conker': 1,\n         'fur': 31,\n         'platform': 37,\n         'beats': 80,\n         'mediocre': 288,\n         'super': 401,\n         'sunshine': 95,\n         '9': 633,\n         'movies': 6077,\n         'dave': 109,\n         'dreamer': 9,\n         'local': 705,\n         'hero': 821,\n         'holds': 238,\n         'viewer': 1016,\n         'lightweight': 29,\n         'seldom': 64,\n         'oscars': 123,\n         'whoever': 157,\n         'casting': 502,\n         'soapdish': 7,\n         'deserves': 474,\n         'after': 6110,\n         'knows': 714,\n         'coming': 859,\n         'enjoyable': 679,\n         'watch': 5605,\n         'how': 7067,\n         'various': 458,\n         'facets': 18,\n         'develop': 209,\n         'true': 1873,\n         'entirely': 427,\n         'fitting': 116,\n         'soap': 220,\n         'opera': 296,\n         'background': 489,\n         'favorite': 1010,\n         'comes': 1977,\n         'whoopi': 61,\n         'goldberg': 82,\n         'write': 529,\n         'sh': 83,\n         'unfortunate': 174,\n         'website': 92,\n         'censors': 34,\n         'insist': 41,\n         'unnecessary': 237,\n         'sanitation': 2,\n         'boring': 1454,\n         'tries': 1024,\n         'effects': 1752,\n         'borrowed': 66,\n         'creative': 295,\n         'jeunet': 7,\n         'am√©lie': 3,\n         'poulain': 3,\n         'dialogs': 116,\n         'worst': 2198,\n         'ever': 4814,\n         'heard': 849,\n         'guillaume': 4,\n         'canet': 1,\n         'convincing': 425,\n         'badly': 522,\n         'dislike': 123,\n         'since': 2265,\n         'le': 105,\n         'pacte': 2,\n         'des': 47,\n         'loups': 2,\n         'brotherhood': 15,\n         'wolf': 89,\n         'christophe': 5,\n         'gans': 2,\n         '80': 472,\n         'year': 1886,\n         'commented': 80,\n         'rated': 393,\n         'saw': 2525,\n         'comments': 610,\n         'thought': 2769,\n         'down': 2992,\n         'guess': 1036,\n         'won': 1332,\n         'problems': 696,\n         'sell': 172,\n         'dvd': 1850,\n         'offered': 137,\n         'such': 4086,\n         'our': 1997,\n         'large': 427,\n         'collection': 276,\n         'am': 2230,\n         'open': 517,\n         'sf': 41,\n         'comedies': 357,\n         'silents': 12,\n         'horror': 2910,\n         'fantasy': 530,\n         'felt': 1223,\n         'lost': 1236,\n         'hour': 940,\n         'half': 1691,\n         'jean': 261,\n         'renoir': 29,\n         'silent': 354,\n         ...})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab()\n"
     ]
    }
   ],
   "source": [
    "#  we are going to map each unique word to a unique integer.\n",
    "## Step 3: encoding each unique token into integers\n",
    "from torchtext.vocab import vocab\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocab = vocab(ordered_dict)\n",
    "vocab.insert_token(\"<pad>\", 0)\n",
    "vocab.insert_token(\"<unk>\", 1)\n",
    "vocab.set_default_index(1)\n",
    "print(vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 27, 206]\n"
     ]
    }
   ],
   "source": [
    "print([vocab[token] for token in ['ceyhun', 'sahin', 'and', 'his', 'family']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "## Step 3-A: define the functions for transformation\n",
    "# text_pipeline function to transform each text in the dataset\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: 1. if x == 'pos' else 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# We will generate batches of samples using DataLoader and pass the data processing pipelines declared previously to the argument collate_fn.\n",
    "## Step 3-B: wrap the encode and transformation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text),dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "    return padded_text_list, label_list, lengths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "## Take a small batch\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=5, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([165,  86, 218, 145, 116])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "length_batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(label_batch.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([165,  86, 218, 145, 116])\n"
     ]
    }
   ],
   "source": [
    "print(length_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 218])\n"
     ]
    }
   ],
   "source": [
    "print(text_batch.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "ShardingFilterIterDataPipe"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 3648,  1075,  3717,  ...,     0,     0,     0],\n        [   88,   121,    11,  ...,     0,     0,     0],\n        [   10,    28,    76,  ...,     0,     0,     0],\n        ...,\n        [    4,  1368,    48,  ...,     0,     0,     0],\n        [  168,    10,   122,  ...,   288,    29,   808],\n        [23224, 19518,    91,  ...,     0,     0,     0]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = next(iter(train_dl))[0]\n",
    "source"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = next(iter(train_dl))[1]\n",
    "target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([510, 293, 352, 129, 129, 282, 184, 133, 249, 392, 220, 248, 224, 214,\n        153, 134, 147,  55, 623, 306, 129, 221, 131, 399, 123, 163, 150,  61,\n        117, 221, 383, 365])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = next(iter(train_dl))[2]\n",
    "lengths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 983])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch, label_batch, length_batch = next(iter(train_dl))\n",
    "text_batch.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_batch.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding layers for sentence encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(\n",
    "    num_embeddings=10, embedding_dim=3, padding_idx=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.8292, -0.9281,  1.6486],\n",
      "         [-0.2286,  0.0294, -1.8128],\n",
      "         [-0.9500,  0.3597,  0.0832],\n",
      "         [ 0.5263,  1.4874, -1.1160]],\n",
      "\n",
      "        [[ 0.5263,  1.4874, -1.1160],\n",
      "         [-1.0165,  0.5236, -0.3098],\n",
      "         [ 0.1645,  0.3430, -0.5329],\n",
      "         [-0.7423,  0.2471, -1.1142]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# a batch of 2 samples of 4 indices each\n",
    "text_encoded_input = torch.LongTensor([[1,2,3,4], [4,5,6,7]])\n",
    "print(embedding(text_encoded_input))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building an RNN model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = hidden[-1,:,:]\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "model = RNN(64,32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2866],\n        [-0.0270],\n        [-0.2858],\n        [-0.0062],\n        [-0.1359]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(5, 3, 64))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building an RNN model for the sentiment analysis task"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = torch.nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = torch.nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1,:,:]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "69025"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "RNN(\n  (embedding): Embedding(69025, 20, padding_idx=0)\n  (rnn): LSTM(20, 64, batch_first=True)\n  (fc1): Linear(in_features=64, out_features=64, bias=True)\n  (relu): ReLU()\n  (fc2): Linear(in_features=64, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim,rnn_hidden_size, fc_hidden_size)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### we will develop the train function to train the model on the given dataset for one epoch and return the classification accuracy and loss:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "    total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### we will develop the evaluate function to measure the model‚Äôs performance on a given dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy: 0.9987  val_accuracy: 1.0000\n",
      "Epoch 1 accuracy: 1.0000  val_accuracy: 1.0000\n",
      "Epoch 2 accuracy: 1.0000  val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f}', f' val_accuracy: {acc_valid:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[  10,  115,  903,  ...,    0,    0,    0],\n         [ 288,    2,  701,  ...,    0,    0,    0],\n         [  92,    4,  489,  ...,    0,    0,    0],\n         ...,\n         [ 118,  123,  192,  ...,    0,    0,    0],\n         [6863, 1767,    6,  ...,    0,    0,    0],\n         [ 624,   10,   51,  ...,    0,    0,    0]]),\n tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0.]),\n tensor([247, 216, 138, 360, 136, 190, 297, 173, 130, 171, 131, 196, 116, 417,\n         140, 189, 256, 169, 266, 220, 177, 446, 126, 358, 259, 210, 234, 217,\n         130,  71, 219, 204]))"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = next(iter(test_dl))\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_IterDataPipeSerializationWrapper instance doesn't have valid length",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py:342\u001B[0m, in \u001B[0;36m_DataPipeSerializationWrapper.__len__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_datapipe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/grouping.py:47\u001B[0m, in \u001B[0;36mShardingFilterIterDataPipe.__len__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe, Sized):\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_datapipe\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_of_instances \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m     48\u001B[0m         (\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance_id \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_of_instances) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instance doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt have valid length\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m))\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:140\u001B[0m, in \u001B[0;36mShufflerIterDataPipe.__len__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe, Sized):\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatapipe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instance doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt have valid length\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m))\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/callable.py:128\u001B[0m, in \u001B[0;36mMapperIterDataPipe.__len__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe)\n\u001B[0;32m--> 128\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instance doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt have valid length\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m    130\u001B[0m )\n",
      "\u001B[0;31mTypeError\u001B[0m: MapperIterDataPipe instance doesn't have valid length",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m acc_test, _ \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc_test\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[37], line 11\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(dataloader)\u001B[0m\n\u001B[1;32m      9\u001B[0m         total_acc \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m ((pred\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat() \u001B[38;5;241m==\u001B[39m label_batch)\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     10\u001B[0m         total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;241m*\u001B[39mlabel_batch\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_acc\u001B[38;5;241m/\u001B[39m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m, total_loss\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataloader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Dataspell_1_env/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py:344\u001B[0m, in \u001B[0;36m_DataPipeSerializationWrapper.__len__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_datapipe)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m--> 344\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    345\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instance doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt have valid length\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m    346\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: _IterDataPipeSerializationWrapper instance doesn't have valid length"
     ]
    }
   ],
   "source": [
    "acc_test, _ = evaluate(test_dl)\n",
    "print(f'test_accuracy: {acc_test:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w = np.zeros((5,5)); w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        w[i][j] = float(((i-j)**2)/16) #as per formula, for this competition, N=5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "actuals = np.array([4, 4, 3, 4, 4, 4, 1, 1, 2, 1])\n",
    "preds   = np.array([0, 2, 1, 0, 0, 0, 1, 1, 2, 1])\n",
    "O = confusion_matrix(actuals, preds); O"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N=5\n",
    "\n",
    "act_hist=np.zeros([N])\n",
    "for item in actuals:\n",
    "    act_hist[item]+=1\n",
    "\n",
    "pred_hist=np.zeros([N])\n",
    "for item in preds:\n",
    "    pred_hist[item]+=1\n",
    "print(act_hist)\n",
    "print(pred_hist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Actuals value counts:{act_hist}, Prediction value counts:{pred_hist}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "E = np.outer(act_hist, pred_hist); E"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "E = E/E.sum(); E.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "O = O/O.sum(); O.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "E"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "O"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Weighted Kappa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num=0\n",
    "den=0\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        num+=w[i][j]*O[i][j]\n",
    "        den+=w[i][j]*E[i][j]\n",
    "\n",
    "weighted_kappa = (1 - (num/den)); weighted_kappa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "counter = Counter([\"a\", \"a\", \"b\", \"b\", \"b\"])\n",
    "print(counter)\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "v1 = vocab(ordered_dict)\n",
    "print(v1['a']) #prints 1\n",
    "print(v1['out of vocab']) #raise RuntimeError since default index is not set\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens = ['e', 'd', 'c', 'b', 'a']\n",
    "#adding <unk> token and default index\n",
    "unk_token = '<unk>'\n",
    "default_index = -1\n",
    "v2 = vocab(OrderedDict([(token, 1) for token in tokens]), specials=[unk_token])\n",
    "v2.set_default_index(default_index)\n",
    "print(v2['<unk>']) #prints 0\n",
    "print(v2['out of vocab']) #prints -1\n",
    "#make default index same as index of unk_token\n",
    "v2.set_default_index(v2[unk_token])\n",
    "v2['out of vocab'] is v2[unk_token] #prints True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "()"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
